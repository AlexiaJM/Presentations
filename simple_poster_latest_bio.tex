%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

% add logos, mention biased gradients

\documentclass[t]{beamer}

\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.

%\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.

%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{animate}
\usepackage{bbm}
\usepackage{pifont}
\usepackage{booktabs} % Top and bottom rules for tables
\usepackage{marginnote}
\usepackage{subfig}


%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Relativistic GANs]{\includegraphics[width=.03\textwidth]{catleft3.png} The relativistic discriminator \includegraphics[width=.03\textwidth]{catright3.png} \\ \includegraphics[width=.03\textwidth]{surprise.png}  a key element missing from  standard GAN \includegraphics[width=.03\textwidth]{surprise.png}} % The short title appears at the bottom of every slide, the full title is only on the title page

\author{Alexia Jolicoeur-Martineau} % Your name
\institute[] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
\textit{alexia.jolicoeur-martineau@mail.mcgill.ca} % Your email address
}

% logo of my university
\titlegraphic{\includegraphics[width=6cm]{DREAM_BIG_logo}\hspace*{.1cm}~%
	\includegraphics[width=6cm]{ladydavis}
}

\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

%\begin{frame}
%\frametitle{Overview} % Table of contents slide, comment this block out to remove it
%\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
%\end{frame}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

%------------------------------------------------
\section{Standard GAN} % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------

\subsection{Subsection Example} % A subsection can be created just before a set of slides with a common theme to further break down your presentation into chunks

\begin{frame}
\frametitle{Standard GAN}
\includegraphics[scale=.25]{GAN.jpg}\\
{\tiny Image from Chris Olah (https://twitter.com/ch402/status/793911806494261248)}
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{G and D with images}
\includegraphics[scale=.50]{cnn.png}

\begin{itemize}
\item We start with 100 random $z_i \sim Normal(0,1)$ variables (pure noise)
\begin{itemize}
	\item The generator $G$ transform noise into an image with deconvolution layers
	(64x64x3 = an image of 64x64 pixels with 3 colors) \\~\\
	
	\item The discriminator $D$ takes a single image and transform it into a single number (the probability that the image is real) using convolution layers
\end{itemize}
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Standard GAN}
\centering
\animategraphics[loop,controls,width=175pt]{10}{DCGAN-}{0}{17}
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Other uses than images}

I focus mostly on images, but you can generate any kind of data.
Furthermore, we can do other things:

\begin{itemize}
	\item Generate data conditionally on a label (e.g. generate an image of cat vs dog, generate a healthy MRI vs one with a tumor)
	
	
	
	
	
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Examples of use: Conditional GAN}

\includegraphics[scale=.50]{use4.png}

BigGAN, Arxiv: 1809.11096.

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Examples of use: Conditional GAN}

\centering
\includegraphics[scale=.40]{use5.png}
https://arxiv.org/pdf/1807.10225.pdf

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Other uses than images}

I focus mostly on images, but you can generate any kind of data.
Furthermore, we can do other things:

\begin{itemize}
	\item Generate data conditionally on a label (e.g. generate an image of cat vs dog, generate a healthy MRI vs one with a tumor)
	
	\item Domain translation (data from domain A transformed into its equivalent in domain B)
	
\end{itemize}
\end{frame}


%------------------------------------------------

\begin{frame}
\frametitle{Examples of use: Domain translation}

\begin{figure}
	\centering
	\subfloat[MRI T1 to T2]{\includegraphics[scale=.25]{use1.png}}%
	\qquad
	\subfloat[Cat to Dog]{\includegraphics[scale=.28]{use2.png}}%
	\caption{Arxiv: 1806.07777 and 1808.04325}%
\end{figure}

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Other uses than images}

I focus mostly on images, but you can generate any kind of data.
Furthermore, we can do other things:

\begin{itemize}
	\item Generate data conditionally on a label (e.g. generate an image of cat vs dog, generate a healthy MRI vs one with a tumor)
	
	\item Domain translation (data from domain A transformed into its equivalent in domain B)
	
	\item Generate data and then use it to augment your small dataset so that your sample size is more reasonable for your analyses (data augmentation)
\end{itemize}
\end{frame}


%------------------------------------------------

\begin{frame}
\frametitle{Examples of use: Data augmentation}

Example case: You have many images of fractures, but very few of certain types. You train a generator and have it produce images of the very rare types of fracture. 

1) You augment your dataset with these images to reduce the class imbalances. 

2) You use these images to help train doctors better since now you can give them more examples of these rare fractures.

\includegraphics[scale=.25]{use3.png}
Arxiv: 1812.01547

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Other uses than images}

I focus mostly on images, but you can generate any kind of data.
Furthermore, we can do other things:

\begin{itemize}
	\item Generate data conditionally on a label (e.g. generate an image of cat vs dog, generate a healthy MRI vs one with a tumor)
	
	\item Domain translation (data from domain A transformed into its equivalent in domain B)
	
	\item Generate data and then use it to augment your small dataset so that your sample size is more reasonable for your analyses (data augmentation)
	
	\item Super-resolution (Enhance)
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Examples of use: Enhance!}

\centering
\includegraphics[scale=.40]{use7.png}
https://arxiv.org/ftp/arxiv/papers/1803/1803.01417.pdf

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Simple explanation}

\begin{itemize}
	\item $x$ is the image (real or fake)
	\item $D$ is trained so $D(x_{real}) \to 1$ and $D(x_{fake}) \to 0$
	\item Therefore, $D(x) \approx P(x \text{ is real}) \in [0,1]$ \\~\\
	\item How does the generator learn to generate realistic images? 
	\item By fooling the discriminator into thinking that fake images are actually real images. \\ i.e., G learns by making $D(x_{fake}) \to 1$ \\~\\
	\item When $D$ cannot distinguish real from fake images $(D(x_{real})=D(x_{fake})=1/2)$, the generator has won the game.
\end{itemize}

\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Two formulations}
	
	\textbf{Saturating GAN}
\begin{equation}
\min_G \max_D \mathbb{E}_{x_r \sim \mathbb{P}}\left[ f_1(D(x_r)) \right] + \mathbb{E}_{z \sim \mathbb{P}_z} \left[ f_2(D(G(z))) \right]
\end{equation}

Neat mathematically but leads to convergence problems. \\~\\

\textbf{Non-saturating GAN}
\begin{equation}
\max_D \mathbb{E}_{x_r \sim \mathbb{P}}\left[ f_1(D(x_r)) \right] + \mathbb{E}_{z \sim \mathbb{P}_z} \left[ f_2(D(G(z))) \right]
\end{equation}
\begin{equation}
\max_G \mathbb{E}_{z \sim \mathbb{P}_z} \left[ f_1(D(G(z))) \right]
\end{equation}

Can be interpreted as fooling $D$ into thinking that fake images are real.

\begin{itemize}
	\item $f_1$, $f_2$ are scalar-to-scalar functions
	\item $\mathbb{P}$ is the distribution of real data
	\item $\mathbb{P}_z \sim \mathcal{N}(0,1)$ is the distribution of the noise
	\item $\mathbb{Q}$ is the distribution of fake data (formed by $G(z)$, $z \sim \mathbb{P}_z$)
	\item $D(x)=\text{a}(C(x))$, $a$ is the activation function, $C(x) \in \mathbb{R}$ is the critic.
\end{itemize}

\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Divergences}
	Finding the optimal $D$ is equivalent to estimating a divergence:
	\vspace*{-5pt}
	$$\max_D \mathbb{E}_{x_r \sim \mathbb{P}}\left[ f_1(D(x_r)) \right] + \mathbb{E}_{z \sim \mathbb{P}_z} \left[ f_2(D(G(z))) \right] \approx Div(\mathbb{P}||\mathbb{Q})$$
	
	\begin{center}
		\textbf{Standard GAN} \\
		$D(x)=\text{sigmoid}(C(x))$ \\
		$f_1(y)=\log(y), f_2(y)=\log(1-y)$ \\
		$Div(\mathbb{P}||\mathbb{Q}) =  JSD(\mathbb{P}||\mathbb{Q})$
	\end{center}
	
	\begin{itemize}
		\item Divergences are distances between probability distributions \\ e.g., Div(domestic cats $||$ wild cats) $<$ Div(domestic cats $||$ fish).
	\end{itemize}
	
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Divergences}
	Finding the optimal $D$ is equivalent to estimating a divergence:
	$$\min_G \max_D \mathbb{E}_{x_r \sim \mathbb{P}}\left[ f_1(D(x_r)) \right] + \mathbb{E}_{z \sim \mathbb{P}_z} \left[ f_2(D(G(z))) \right] \approx \min_G Div(\mathbb{P}||\mathbb{Q})$$ 
	
	\begin{center}
	\textbf{Standard GAN} \\
	$D(x)=\text{sigmoid}(C(x))$ \\
	$f_1(y)=\log(y), f_2(y)=\log(1-y)$ \\
	$Div(\mathbb{P}||\mathbb{Q}) =  JSD(\mathbb{P}||\mathbb{Q})$
	\end{center}
	
	\begin{itemize}
		\item Divergences are distances between probability distributions \\ e.g., Div(domestic cats $||$ wild cats) $<$ Div(domestic cats $||$ fish).
		\item min/max GAN is like estimating and minimizing the divergence \\ (kind of, but not really; see \textit{GANs beyond divergence minimization}).
	\end{itemize}
	
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Divergences}
Finding the optimal $D$ is equivalent to estimating a divergence:
$$\min_G \max_D \mathbb{E}_{x_r \sim \mathbb{P}}\left[ f_1(D(x_r)) \right] + \mathbb{E}_{z \sim \mathbb{P}_z} \left[ f_2(D(G(z))) \right] \approx \min_G Div(\mathbb{P}||\mathbb{Q})$$ 

\begin{center}
	\textbf{Standard GAN} \\
	$D(x)=\text{sigmoid}(C(x))$ \\
	$f_1(y)=\log(y), f_2(y)=\log(1-y)$ \\
	$Div(\mathbb{P}||\mathbb{Q}) =  JSD(\mathbb{P}||\mathbb{Q})$
\end{center}

\begin{itemize}
	\item Divergences are distances between probability distributions \\ e.g., Div(domestic cats $||$ wild cats) $<$ Div(domestic cats $||$ fish).
	\item min/max GAN is like estimating and minimizing the divergence \\ (kind of, but not really; see \textit{GANs beyond divergence minimization}).
	\item Saturating and non-saturating GANs converge to the same optimum
\end{itemize}

\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Problems with GANs}
	
	\begin{enumerate}
		\item mode collapse: only generate certain modes of the data.
		\begin{itemize}
			\item only generating grey cats
			\item only generating from 10 of the 20 groups/clusters of data
		\end{itemize}
	\end{enumerate}
	
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Problems with GANs}
	
	\begin{enumerate}
		\item mode collapse: only generate certain modes of the data.
		\begin{itemize}
			\item only generating grey cats
			\item only generating from 10 of the 20 groups/clusters of data
		\end{itemize}
		\item severe instability, especially in high dimension (high res images)
	\end{enumerate}
	
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Problems with GANs}
	
	\begin{enumerate}
		\item mode collapse: only generate certain modes of the data.
		\begin{itemize}
			\item only generating grey cats
			\item only generating from 10 of the 20 groups/clusters of data
		\end{itemize}
		\item severe instability, especially in high dimension (high res images)
		\item $D$ can easily become too good at distinguishing real from fake early in training. In SGAN this leads to vanishing gradients (with high-variance), which means that $G$ stop learning.
	\end{enumerate}

	Relativistic GANs improve 2 and 3 \includegraphics[width=0.03\linewidth]{happy.png}, but not 1 \includegraphics[width=0.03\linewidth]{sad.png}. 
	
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Key missing property}
	
	Key property missing from GANs: \\
	\textit{Increasing $D(x_{fake})$ should simultaneously \textbf{decrease} $D(x_{real})$.} \\~\\
	Less formally (for SGAN): \\
	\textit{Increasing $P(x_{fake} \text{ is real})$ should simultaneously \textbf{decrease} $P(x_{real} \text{ is real})$.} \\~\\
	\includegraphics[width=.50\linewidth]{whatwewant.png}
	
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{1) Divergence minimization}
	\includegraphics[width=1\linewidth]{Figure1-1_3.png}
\end{frame}



%------------------------------------------------

\begin{frame}
	\frametitle{1) Divergence minimization}
	\includegraphics[width=1\linewidth]{Figure1-1_2.png}
\end{frame}



%------------------------------------------------

\begin{frame}
	\frametitle{1) Divergence minimization}
	\includegraphics[width=1\linewidth]{Figure1-1.png}
\end{frame}


%------------------------------------------------

\begin{frame}
	\frametitle{1) Divergence minimization}
	\includegraphics[width=1\linewidth]{Figure1-1.png} \\~\\ 
	SGAN is not like divergence minimization \includegraphics[width=0.04\linewidth]{sad.png}. \\
	With the key missing property, it is like divergence minimization \includegraphics[width=0.04\linewidth]{happy.png}.
\end{frame}


%------------------------------------------------

\begin{frame}
	\frametitle{2) Ignoring prior information}
	
	Imagine SGAN is a card game in real-life. 
	\begin{itemize}
		\item Diamond cards are real samples
		\item mini-batch = 4 cards (2 fake, 2 real)
		\item You are $D$, you estimate $D(x)$=$P(x \text{ is real})$
	\end{itemize} \vspace{.10cm}
	Let say that the current mini-batch is:
	\centering
	\includegraphics[width=0.75\linewidth]{easy_1.png}
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{2) Ignoring prior information}
	
	Imagine SGAN is a card game in real-life. 
	\begin{itemize}
		\item Diamond cards are real samples
		\item mini-batch = 4 cards (2 fake, 2 real)
		\item You are $D$, you estimate $D(x)$=$P(x \text{ is real})$
	\end{itemize} \vspace{.10cm}
	Let say that the current mini-batch is:
	\centering
	\includegraphics[width=0.75\linewidth]{easy_2.png}
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{2) Ignoring prior information}
	
	Imagine SGAN is a card game in real-life. 
	\begin{itemize}
		\item Diamond cards are real samples
		\item mini-batch = 4 cards (2 fake, 2 real)
		\item You are $D$, you estimate $D(x)$=$P(x \text{ is real})$
	\end{itemize} \vspace{.10cm}
	Let say that the current mini-batch is:
	\centering
	\includegraphics[width=0.75\linewidth]{easy_3.png}
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{2) Ignoring prior information}
	
	Imagine SGAN is a card game in real-life. 
	\begin{itemize}
		\item Diamond cards are real samples
		\item mini-batch = 4 cards (2 fake, 2 real)
		\item You are $D$, you estimate $D(x)$=$P(x \text{ is real})$
	\end{itemize} \vspace{.10cm}
	Let say that $G$ trained well so the next mini-batch is:
	\centering
	\includegraphics[width=0.75\linewidth]{hard_1.png}
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{2) Ignoring prior information}
	
	Imagine SGAN is a card game in real-life. 
	\begin{itemize}
		\item Diamond cards are real samples
		\item mini-batch = 4 cards (2 fake, 2 real)
		\item You are $D$, you estimate $D(x)$=$P(x \text{ is real})$
	\end{itemize} \vspace{.10cm}
	Let say that $G$ trained well so the next mini-batch is:
	\centering
	\includegraphics[width=0.75\linewidth]{hard_2.png}
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{2) Ignoring prior information}
	
	Imagine SGAN is a card game in real-life. 
	\begin{itemize}
		\item Diamond cards are real samples
		\item mini-batch = 4 cards (2 fake, 2 real)
		\item You are $D$, you estimate $D(x)$=$P(x \text{ is real})$
	\end{itemize} \vspace{.10cm}
	Let say that $G$ trained well so the next mini-batch is:
	\centering
	\includegraphics[width=0.75\linewidth]{hard_3.png} \\
	SGAN ignores the fact that half the cards are real, SGAN doesn't see the broad picture because it only looks at one image at a time.
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Relativistic Discriminator}
	Question: How to impose the key missing property? \includegraphics[width=0.04\linewidth]{why.png} \\
	Solution: Relativistic Discriminator! \vspace{.25cm}
	
\end{frame}


%------------------------------------------------

\begin{frame}
	\frametitle{Relativistic Discriminator}
	Question: How to impose the key missing property? \includegraphics[width=0.04\linewidth]{why.png} \\
	Solution: Relativistic Discriminator! \vspace{.25cm}
	
	\textbf{Non-relativistic:} \\ $D(x)=\text{a}(C(x))$, $a$ is the activation function, $C(x) \in \mathbb{R}$. \\ \vspace{.10cm}
	
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Relativistic Discriminator}
	Question: How to impose the key missing property? \includegraphics[width=0.04\linewidth]{why.png} \\
	Solution: Relativistic Discriminator! \vspace{.25cm}
	
	\textbf{Non-relativistic:} \\ $D(x)=\text{a}(C(x))$, $a$ is the activation function, $C(x) \in \mathbb{R}$. \\ \vspace{.10cm}
	\textbf{Relativistic:} \\ Sample from real/fake data pairs $\tilde{x}=(x_r,x_f)$, $D(\tilde{x}) = \text{a}(C(x_r)-C(x_f))$. \\
	Relativistic SGAN: $D(\tilde{x}) \approx P(x_r \text{ is more realistic than } x_f)$ \\
	IPM GANs: Special case where $\text{a}(y)=y$ and we use an IPM constraint. \\ \vspace{.10cm}
	
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Relativistic Discriminator}
	Question: How to impose the key missing property? \includegraphics[width=0.04\linewidth]{why.png} \\
	Solution: Relativistic Discriminator! \vspace{.25cm}
	
	\textbf{Non-relativistic:} \\ $D(x)=\text{a}(C(x))$, $a$ is the activation function, $C(x) \in \mathbb{R}$. \\ \vspace{.10cm}
	\textbf{Relativistic:} \\ Sample from real/fake data pairs $\tilde{x}=(x_r,x_f)$, $D(\tilde{x}) = \text{a}(C(x_r)-C(x_f))$. \\
	Relativistic SGAN: $D(\tilde{x}) \approx P(x_r \text{ is more realistic than } x_f)$ \\
	IPM GANs: Special case where $\text{a}(y)=y$ and we use an IPM constraint. \\ \vspace{.10cm}
	\textbf{Relativistic average:} \\ 
	$\tilde{D}(x_r)=\text{a} \left( C(x_r)-\mathbb{E}_{x_f \sim \mathbb{Q}} C(x_f) \right)$ \\ $\tilde{D}(x_f)=\text{a} \left( C(x_f)-\mathbb{E}_{x_r \sim \mathbb{P}} C(x_r) \right)$ \\ \vspace{.25cm}
	
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Relativistic Discriminator}
Question: How to impose the key missing property? \includegraphics[width=0.04\linewidth]{why.png} \\
Solution: Relativistic Discriminator! \vspace{.25cm}

	\textbf{Non-relativistic:} \\ $D(x)=\text{a}(C(x))$, $a$ is the activation function, $C(x) \in \mathbb{R}$. \\ \vspace{.10cm}
\textbf{Relativistic:} \\ Sample from real/fake data pairs $\tilde{x}=(x_r,x_f)$, $D(\tilde{x}) = \text{a}(C(x_r)-C(x_f))$. \\
Relativistic SGAN: $D(\tilde{x}) \approx P(x_r \text{ is more realistic than } x_f)$ \\
IPM GANs: Special case where $\text{a}(y)=y$ and we use an IPM constraint. \\ \vspace{.10cm}
\textbf{Relativistic average:} \\ 
$\tilde{D}(x_r)=\text{a} \left( C(x_r)-\mathbb{E}_{x_f \sim \mathbb{Q}} C(x_f) \right)$ \\ $\tilde{D}(x_f)=\text{a} \left( C(x_f)-\mathbb{E}_{x_r \sim \mathbb{P}} C(x_r) \right)$ \\ \vspace{.25cm}
Making $D$ relativistic  gives us the key property missing and it works with any GAN! \includegraphics[width=0.04\linewidth]{happy.png} It also improves stability and generated data quality! \includegraphics[width=0.04\linewidth]{surprise.png}

\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Relativistic Discriminator}
	Relativistic Standard GAN (RSGAN):
	\begin{equation}
	\max_C \mathbb{E}_{(x_r,x_f) \sim (\mathbb{P},\mathbb{Q})}\left[ \log (\text{sigmoid}(C(x_r)-C(x_f))) \right].
	\end{equation}
	\begin{equation}
	\max_G \mathbb{E}_{(x_r,x_f) \sim (\mathbb{P},\mathbb{Q})}\left[ \log (\text{sigmoid}(C(x_f)-C(x_r))) \right].
	\end{equation}
	\\ Note that $\log(D(x_r,x_f))=\log(1-D(x_f,x_r))$ so we do not need two terms. \\ \vspace{.75cm}
	Relativistic average Standard GAN (RaSGAN):
	\begin{equation}
	\max_D \mathbb{E}_{x_r \sim \mathbb{P}}\left[ \log\left( \tilde{D}(x_r) \right) \right] + \mathbb{E}_{x_f \sim \mathbb{Q}} \left[ \log \left( 1 - \tilde{D}(x_f) \right) \right]
	\end{equation} 
	\begin{equation}
	\max_G \mathbb{E}_{x_f \sim \mathbb{Q}}\left[ \log\left( \tilde{D}(x_f) \right) \right] + \mathbb{E}_{x_r \sim \mathbb{P}} \left[ \log \left( 1 - \tilde{D}(x_r) \right) \right]
	\end{equation}
	$\tilde{D}(x_r)=\text{sigmoid} \left( C(x_r)-\mathbb{E}_{x_f \sim \mathbb{Q}} C(x_f) \right)$ \\ $ \tilde{D}(G(z))=\text{sigmoid} \left( C(x_f)-\mathbb{E}_{x_r \sim \mathbb{P}} C(x_r) \right)$

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Relativistic Divergence}
Relativistic paired GANs (RpGANs):
\begin{equation}
\max_C \mathbb{E}_{(x_r,x_f) \sim (\mathbb{P},\mathbb{Q})}\left[f(C(x_r)-C(x_f)) \right].
\end{equation}
\begin{equation}
\max_G \mathbb{E}_{(x_r,x_f) \sim (\mathbb{P},\mathbb{Q})}\left[f(C(x_f)-C(x_r)) \right].
\end{equation}
Relativistic average Standard GAN (RaGANs):
\begin{equation}
\max_C \mathbb{E}_{x_r \sim \mathbb{P}}\left[ \log\left( \tilde{D}(x_r) \right) \right] + \mathbb{E}_{x_f \sim \mathbb{Q}} \left[ \log \left( 1 - \tilde{D}(x_f) \right) \right]
\end{equation} 
\begin{equation}
\max_G \mathbb{E}_{x_f \sim \mathbb{Q}}\left[ \log\left( \tilde{D}(x_f) \right) \right] + \mathbb{E}_{x_r \sim \mathbb{P}} \left[ \log \left( 1 - \tilde{D}(x_r) \right) \right]
\end{equation}
$\tilde{D}(x_r)=\text{sigmoid} \left( C(x_r)-\mathbb{E}_{x_f \sim \mathbb{Q}} C(x_f) \right)$ \\ $ \tilde{D}(G(z))=\text{sigmoid} \left( C(x_f)-\mathbb{E}_{x_r \sim \mathbb{P}} C(x_r) \right)$

\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Results - CIFAR10 (50k 32x32 images from 10 classes)}

{\small \begin{table}
	\caption{Frechet Inception Distance (FID) at $100k$ generator iterations, using spectral normalization in $D$ and batch norm in $G$.}
	\label{CIFAR10}
	\centering
	\begin{tabular}{ccc}
		\toprule
		& $lr=.0002$ & $lr=.0001$ \\
		& $\beta=(.50,.999)$ & $\beta=(.50,.9)$ \\
		Loss & $n_D=1$ & $n_D=5$ \\
		\cmidrule(){1-3}
		SGAN & 40.64 & 41.32 \\
		RSGAN & 36.61 & 55.29 \\
		RaSGAN & 31.98 &  37.92  \\
		\cmidrule(){1-3}
		LSGAN &  29.53 & 187.01 \\
		RaLSGAN &  30.92 & 219.39 \\
		\cmidrule(){1-3}
		HingeGAN & 49.53 & 80.85 \\
		RaHingeGAN & 39.12 &  37.72 \\
		\cmidrule(){1-3}
		WGAN-GP & 83.89 & \textbf{27.81} \\
		RSGAN-GP & \textbf{25.60} &  28.13 \\
		RaSGAN-GP & 331.86 &  \\
		\bottomrule
	\end{tabular}
\end{table}}

\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Results - CAT (low res images of cats)}
	
\small \begin{table}
	\caption{Frechet Inception Distance (FID) at 20k, 30k \ldots , 100k generator iterations, using $lr=.0002$, $\beta=(.50,.999)$, $n_D=1$, and batch norm (BN) in $D$ and $G$.}
	\centering
	\begin{tabular}{ccccc}
		\toprule
		Loss & Min & Max & Mean & SD \\
		\cmidrule{1-5}
		\multicolumn{5}{c}{64x64 images (N=9304)} \\
		SGAN & 16.56 & 310.56 & 52.54 & 96.81 \\
		RSGAN & 19.03 & 42.05 & 32.16 & 7.01 \\
		RaSGAN & 15.38 & 33.11 & 20.53 & 5.68 \\
		\cmidrule{1-5}
		LSGAN & 20.27 & 224.97 & 73.62 & 61.02 \\
		RaLSGAN & \textbf{11.97} & \textbf{19.29} & \textbf{15.61} & 2.55 \\
		\cmidrule{1-5}
		HingeGAN & 17.60 & 50.94 & 32.23 & 14.44 \\
		RaHingeGAN & 14.62 & 27.31 & 20.29 & 3.96 \\
		\cmidrule{1-5}
		RSGAN-GP & 16.41 & 22.34 & 18.20 & 1.82 \\
		RaSGAN-GP & 17.32 & 22 & 19.58 & \textbf{1.81} \\
	\end{tabular}
\end{table}
	
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Results - CAT (high res images of cats)}
	
	\small \begin{table}
		\centering
		\begin{tabular}{ccccc}
			\toprule
			Loss & Min & Max & Mean & SD \\
			\cmidrule{1-5}
			\multicolumn{5}{c}{128x128 images (N=6645)} \\
			SGAN & - & - & - & - \\
			RaSGAN & 21.05 & \textbf{39.65} & 28.53 & \textbf{6.52} \\
			\cmidrule{1-5}
			LSGAN & 19.03 & 51.36 & 30.28 & 10.16 \\
			RaLSGAN & \textbf{15.85} & 40.26 & \textbf{22.36} & 7.53 \\
			\cmidrule{1-5}
			\multicolumn{5}{c}{256x256 images (N=2011)} \\
			SGAN & - & - & - & - \\
			RaSGAN & \textbf{32.11} & 102.76 & \textbf{56.64} & 21.03 \\
			SpectralSGAN & 54.08 & \textbf{90.43} & 64.92 & \textbf{12.00} \\
			\cmidrule{1-5}
			LSGAN & - & - & - & - \\
			RaLSGAN & 35.21 & 299.52 & 70.44 & 86.01 \\
			\cmidrule{1-5}
			WGAN-GP & 155.46 & 437.48 & 341.91 & 101.11 \\
		\end{tabular}
	\end{table}
	
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Results - CAT256}
	
\begin{figure}[H]
	\centering
	\includegraphics[width=75pt]{GAN.jpeg}
	\caption{256x256 cats with GAN (5k iterations)}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=75pt]{LSGAN.jpeg}
	\caption{256x256 cats with LSGAN (5k iterations)}
\end{figure}
\end{frame}


\begin{frame}
	\frametitle{Results - CAT256}

\begin{figure}[H]
	\centering
	\includegraphics[width=180pt]{RaSGAN.jpeg}
	\caption{256x256 cats with RaSGAN (FID = 32.11)}
\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Results - CAT256}

\begin{figure}[H]
	\centering
	\includegraphics[width=180pt]{RaLSGAN.jpeg}
	\caption{256x256 cats with RaLSGAN (FID = 35.21)}
\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Results - CAT256}

\begin{figure}[H]
	\centering
	\includegraphics[width=180pt]{SpectralSGAN.jpeg}
	\caption{256x256 cats with SpectralSGAN (FID = 54.73)}
\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Results - CAT256}


\begin{figure}[H]
	\centering
	\includegraphics[width=180pt]{WGAN-GP.jpeg}
	\caption{256x256 cats with WGAN-GP (FID $>$ 100)}
\end{figure}

\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Paper conclusion}
\begin{enumerate}
	\item $D$ should be relativistic
	\item RGANs or RaGANs = Enhanced stability
	\item RaGANs = Higher quality of generated data
	\item RGANs and RaGANs can obtain state-of-the-art WGAN-GP results while speeding up computations by AT LEAST 3 times
	\item RaGANs can generate high res images from scratch, while Standard GAN and Least Squares GAN cannot
	\item high-dimensional small datasets, such as CAT, are challenging and thus great for testing GANs
\end{enumerate}

\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{Applications (ESRGAN)}
	\begin{itemize}
		\item Xintao Wang et al. (2018) used a Standard RaGAN to win first place in the PIRM2018-SR competition (region 3) and obtain the best perceptual index.
	\end{itemize}
	\centering
	\includegraphics[width=350pt]{ESRGAN.jpg}
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Applications (ESRGAN)}
	\begin{itemize}
	\item ESRGAN is now used in video game emulation to enhance the quality of textures in old video games!
	\item See: https://www.reddit.com/r/GameUpscale/
	\includegraphics[width=0.04\linewidth]{happy.png}
\end{itemize}
\begin{figure}
	\centering
	\subfloat{\includegraphics[scale=.25]{frame1.png}}%
	\qquad
	\subfloat{\includegraphics[scale=.25]{frame2.png}}%
\end{figure}
\end{frame}

%------------------------------------------------

\begin{frame}
	\frametitle{\includegraphics[width=.03\textwidth]{catleft3.png} Relativistic-$f$ divergences \includegraphics[width=.03\textwidth]{catright3.png}}
	In my last paper:
	\begin{itemize}
		\item I introduce more variants of Relativistic GANs
		\item I mathematically prove that Relativistic GANs (and variants) are actual divergences using any concave function $f$ with certain basic properties.
		\item I show that RaGANs are biased, but the bias is small and negligible with a batch size $\geq 32$. Also, interestingly, RaLSGAN bias has a simple closed form and it can be easily removed.
	\end{itemize}
	
	This paper provide a stronger mathematical foundation to my approach. \\
	
	See: https://arxiv.org/abs/1901.02474
\end{frame}


%------------------------------------------------

\begin{frame}
	\frametitle{Final comments}
	
	\begin{itemize}
	\item I did this work alone without supervision. Everything was run on my single GPU, a Geforce 1060. Every night, I booted my computer on Ubuntu and trained a few models. \vspace{.25cm}
	
	\item This is already my most cited paper at 31 citations! It beats my grant-funded multi-author papers from 2015.
	
	\item I only scratched the surface of Relativistic GANs, there is so much potentially interesting variants to study. 
	
	\item \textbf{Make sure to use a relativistic discriminator for best results!}
	\end{itemize}
	
\end{frame}

%------------------------------------------------

%\begin{frame}
%	\frametitle{}
%	
%\begin{center}
%	\begin{tabular}{ccc}
%		\includegraphics[width=.25\linewidth]{CIHR.png} \\ \\ %\includegraphics[width=0.5\linewidth]{HBHL.png} \\ \\ \includegraphics[width=0.5\linewidth]{FRSQ.png}
%	\end{tabular}
%\end{center}
%\end{frame}

%------------------------------------------------

\begin{frame}
\Huge{\centerline{The End}}
\end{frame}

%----------------------------------------------------------------------------------------

\end{document}